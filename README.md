# intership_1 _ VIETNAM-ENGLISH BILINGUAL NEWS HEADLINE CLASSIFICATION BY PRE-TRAINED MODELS

In recent years, the exponential growth of digital media has led to an overwhelming influx of
news articles in different languages. This has created a pressing need for methods to classify
news headlines accurately and efficiently. 
Vietnamese or English. User
simple just input text or news headline in 5 topics, sports, entertainment, politics, business,
and technology, the model will return results based on that


it illustrates that pre-trained model outperformance compared to
traditional approaches. And we observe that our results become better via different variants of
BERT, from multi BERT to the application of a combination of XLM and BERT, it is called
XLM-RoBERTA. The results of the best model, XLM-RoBERTA, are nearly 90%. 
